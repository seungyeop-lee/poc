'use client';

import { useRef, useState, useEffect, useCallback } from 'react';
import type { VideoEditorProps, DebugInfo, AudioSettings, RecordingState } from '../types';
import { formatTime, calculateOverlayPosition, cleanupObjectUrl } from '../utils';

/**
 * ë¹„ë””ì˜¤ í¸ì§‘ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë©”ì¸ ì»´í¬ë„ŒíŠ¸
 * ë¹„ë””ì˜¤/ì›¹ìº  ìŠ¤íŠ¸ë¦¼ì— ì´ë¯¸ì§€ ì˜¤ë²„ë ˆì´ë¥¼ ì ìš©í•˜ê³  ë…¹í™” ê¸°ëŠ¥ ì œê³µ
 */
export const VideoEditor: React.FC<VideoEditorProps> = ({ 
  videoFile, 
  webcamStream, 
  overlayImage,
  onVideoProcessed,
  watermarkPosition = 'top-right'
}) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioStreamRef = useRef<MediaStream | null>(null);
  const audioSourcesRef = useRef<Set<MediaElementAudioSourceNode>>(new Set());
  const gainNodeRef = useRef<GainNode | null>(null);
  
  const [overlayImageElement, setOverlayImageElement] = useState<HTMLImageElement | null>(null);
  const [recordingState, setRecordingState] = useState<RecordingState>({
    isRecording: false,
    recordingTime: 0,
    recordedChunks: [],
    downloadUrl: null
  });
  const [audioSettings, setAudioSettings] = useState<AudioSettings>({
    enabled: false,
    detectedElements: 0,
    gainLevel: 1.0
  });
  const [debugInfo, setDebugInfo] = useState<DebugInfo>({
    canvasWidth: 0,
    canvasHeight: 0,
    videoWidth: 0,
    videoHeight: 0,
    readyState: 0,
    sourceType: 'ì—†ìŒ'
  });

  // ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ë¡œë“œ
  useEffect(() => {
    const img = new Image();
    img.onload = () => {
      setOverlayImageElement(img);
    };
    img.src = URL.createObjectURL(overlayImage);
    
    return () => {
      cleanupObjectUrl(img.src);
    };
  }, [overlayImage]);

  // ë¹„ë””ì˜¤ ì†ŒìŠ¤ ì„¤ì •
  useEffect(() => {
    const video = videoRef.current;
    if (!video) return;

    if (videoFile) {
      video.src = URL.createObjectURL(videoFile);
      video.load();
    } else if (webcamStream) {
      video.srcObject = webcamStream;
      video.muted = true;
      video.playsInline = true;
      video.play().catch(err => console.warn('ì›¹ìº  ì¬ìƒ ì‹¤íŒ¨:', err));
      
      const checkAndStart = () => {
        if (video.videoWidth > 0 && video.videoHeight > 0) {
          console.log('ì›¹ìº  ë¹„ë””ì˜¤ ì¤€ë¹„ë¨, ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘');
        }
      };
      
      setTimeout(checkAndStart, 100);
    }

    return () => {
      if (videoFile && video.src) {
        cleanupObjectUrl(video.src);
      }
    };
  }, [videoFile, webcamStream]);

  // ìº”ë²„ìŠ¤ì— í”„ë ˆì„ ê·¸ë¦¬ê¸°
  const drawFrame = useCallback(() => {
    const canvas = canvasRef.current;
    const video = videoRef.current;
    const ctx = canvas?.getContext('2d');
    
    if (!canvas || !video || !ctx) return;

    if (webcamStream) {
      if (video.videoWidth === 0 || video.videoHeight === 0) {
        if (canvas.width === 0 && canvas.height === 0) {
          canvas.width = 1920;
          canvas.height = 1080;
        }
        return;
      }
    } else {
      if (video.readyState < 2) return;
    }

    const videoWidth = video.videoWidth || 1920;
    const videoHeight = video.videoHeight || 1080;
    
    if (canvas.width !== videoWidth || canvas.height !== videoHeight) {
      canvas.width = videoWidth;
      canvas.height = videoHeight;
      console.log('ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì •:', { width: videoWidth, height: videoHeight });
    }

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    try {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      
      if (overlayImageElement) {
        const overlaySize = Math.min(canvas.width, canvas.height) * 0.15;
        const margin = overlaySize * 0.2;
        const position = calculateOverlayPosition(canvas.width, canvas.height, overlaySize, watermarkPosition, margin);
        
        ctx.drawImage(overlayImageElement, position.x, position.y, overlaySize, overlaySize);
      }
      
      setDebugInfo({
        canvasWidth: canvas.width,
        canvasHeight: canvas.height,
        videoWidth: video.videoWidth,
        videoHeight: video.videoHeight,
        readyState: video.readyState,
        sourceType: videoFile ? 'íŒŒì¼' : webcamStream ? 'ì›¹ìº ' : 'ì—†ìŒ'
      });
    } catch (error) {
      console.warn('í”„ë ˆì„ ê·¸ë¦¬ê¸° ì˜¤ë¥˜:', error);
    }
  }, [overlayImageElement, webcamStream, videoFile, watermarkPosition]);

  // ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘
  useEffect(() => {
    const video = videoRef.current;
    if (!video) return;

    let animationFrameId: number;
    
    const handleLoadedMetadata = () => {
      console.log('ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œë¨:', {
        videoWidth: video.videoWidth,
        videoHeight: video.videoHeight,
        readyState: video.readyState,
        srcObject: !!video.srcObject,
        src: !!video.src
      });
      
      if (webcamStream) {
        video.play().catch(err => console.warn('ì›¹ìº  ì¬ìƒ ì‹¤íŒ¨:', err));
      }
      
      const startAnimation = () => {
        drawFrame();
        animationFrameId = requestAnimationFrame(startAnimation);
      };
      startAnimation();
    };

    const handleCanPlay = () => {
      console.log('ë¹„ë””ì˜¤ ì¬ìƒ ê°€ëŠ¥ ìƒíƒœ');
      if (!animationFrameId) {
        handleLoadedMetadata();
      }
    };

    video.addEventListener('loadedmetadata', handleLoadedMetadata);
    video.addEventListener('canplay', handleCanPlay);
    
    if (webcamStream && video.srcObject) {
      const timer = setTimeout(() => {
        if (video.videoWidth > 0 && video.videoHeight > 0) {
          handleLoadedMetadata();
        }
      }, 100);
      
      return () => {
        clearTimeout(timer);
        video.removeEventListener('loadedmetadata', handleLoadedMetadata);
        video.removeEventListener('canplay', handleCanPlay);
        if (animationFrameId) {
          cancelAnimationFrame(animationFrameId);
        }
      };
    }
    
    if (video.readyState >= 1) {
      handleLoadedMetadata();
    }

    return () => {
      video.removeEventListener('loadedmetadata', handleLoadedMetadata);
      video.removeEventListener('canplay', handleCanPlay);
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
    };
  }, [drawFrame, webcamStream]);

  // DOM ë³€í™” ê°ì§€ ë° ìƒˆ ì˜¤ë””ì˜¤ ìš”ì†Œ ìë™ ì—°ê²°
  useEffect(() => {
    if (!audioSettings.enabled) return;

    const observer = new MutationObserver((mutations) => {
      mutations.forEach((mutation) => {
        mutation.addedNodes.forEach((node) => {
          if (node.nodeType === Node.ELEMENT_NODE) {
            const element = node as Element;
            
            if (element.tagName === 'AUDIO' || element.tagName === 'VIDEO') {
              connectNewAudioElement(element as HTMLMediaElement);
            }
            
            const audioVideoElements = element.querySelectorAll('audio, video');
            audioVideoElements.forEach((mediaElement) => {
              connectNewAudioElement(mediaElement as HTMLMediaElement);
            });
          }
        });
      });
    });

    observer.observe(document.body, {
      childList: true,
      subtree: true
    });

    return () => {
      observer.disconnect();
    };
  }, [audioSettings.enabled]);

  // ì›¹í˜ì´ì§€ ë‚´ ëª¨ë“  ì˜¤ë””ì˜¤ ìº¡ì²˜ í™œì„±í™”
  const enablePageAudio = async () => {
    try {
      const audioContext = new AudioContext();
      audioContextRef.current = audioContext;

      const gainNode = audioContext.createGain();
      gainNodeRef.current = gainNode;

      const destination = audioContext.createMediaStreamDestination();
      
      gainNode.connect(destination);
      gainNode.connect(audioContext.destination);
      
      const audioVideoElements = document.querySelectorAll('audio, video');
      let connectedCount = 0;

      audioVideoElements.forEach((element) => {
        try {
          const mediaElement = element as HTMLMediaElement;
          
          if (mediaElement.hasAttribute('data-audio-connected')) {
            return;
          }

          const source = audioContext.createMediaElementSource(mediaElement);
          audioSourcesRef.current.add(source);
          
          source.connect(gainNode);
          
          mediaElement.setAttribute('data-audio-connected', 'true');
          connectedCount++;
          
          console.log('ì˜¤ë””ì˜¤ ìš”ì†Œ ì—°ê²°ë¨:', mediaElement.tagName, mediaElement.src || mediaElement.currentSrc);
        } catch (error) {
          console.warn('ì˜¤ë””ì˜¤ ìš”ì†Œ ì—°ê²° ì‹¤íŒ¨:', element, error);
        }
      });
      
      audioStreamRef.current = destination.stream;
      setAudioSettings({
        enabled: true,
        detectedElements: connectedCount,
        gainLevel: 1.0
      });
      
      console.log(`í˜ì´ì§€ ì˜¤ë””ì˜¤ ìº¡ì²˜ í™œì„±í™”ë¨: ${connectedCount}ê°œ ìš”ì†Œ ì—°ê²°`);
    } catch (error) {
      console.error('í˜ì´ì§€ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨:', error);
      setAudioSettings(prev => ({ ...prev, enabled: false }));
    }
  };

  // ìƒˆë¡œ ì¶”ê°€ëœ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ìš”ì†Œ ìë™ ì—°ê²°
  const connectNewAudioElement = (element: HTMLMediaElement) => {
    const audioContext = audioContextRef.current;
    const gainNode = gainNodeRef.current;
    
    if (!audioContext || !gainNode || element.hasAttribute('data-audio-connected')) {
      return;
    }

    try {
      const source = audioContext.createMediaElementSource(element);
      audioSourcesRef.current.add(source);
      source.connect(gainNode);
      element.setAttribute('data-audio-connected', 'true');
      
      setAudioSettings(prev => ({ ...prev, detectedElements: prev.detectedElements + 1 }));
      console.log('ìƒˆ ì˜¤ë””ì˜¤ ìš”ì†Œ ìë™ ì—°ê²°ë¨:', element.tagName);
    } catch (error) {
      console.warn('ìƒˆ ì˜¤ë””ì˜¤ ìš”ì†Œ ì—°ê²° ì‹¤íŒ¨:', error);
    }
  };

  // ë…¹í™” ì‹œì‘
  const startRecording = async () => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    try {
      const stream = canvas.captureStream(30);
      
      if (audioStreamRef.current) {
        const audioTracks = audioStreamRef.current.getAudioTracks();
        audioTracks.forEach(track => {
          stream.addTrack(track);
        });
        console.log('ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ íŠ¸ë™ ì¶”ê°€ë¨:', audioTracks.length);
      } else if (webcamStream) {
        const audioTracks = webcamStream.getAudioTracks();
        audioTracks.forEach(track => {
          stream.addTrack(track);
        });
        console.log('ì›¹ìº  ì˜¤ë””ì˜¤ íŠ¸ë™ ì¶”ê°€ë¨:', audioTracks.length);
      } else {
        console.warn('ì˜¤ë””ì˜¤ê°€ í™œì„±í™”ë˜ì§€ ì•ŠìŒ');
      }

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'video/webm;codecs=vp9,opus'
      });

      mediaRecorderRef.current = mediaRecorder;
      setRecordingState({
        isRecording: true,
        recordingTime: 0,
        recordedChunks: [],
        downloadUrl: null
      });

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          setRecordingState(prev => ({
            ...prev,
            recordedChunks: [...prev.recordedChunks, event.data]
          }));
        }
      };

      mediaRecorder.onstop = () => {
        setRecordingState(prev => ({ ...prev, isRecording: false }));
      };

      mediaRecorder.start(1000);

      const timer = setInterval(() => {
        setRecordingState(prev => ({ ...prev, recordingTime: prev.recordingTime + 1 }));
      }, 1000);

      return () => {
        clearInterval(timer);
      };
    } catch (error) {
      console.error('ë…¹í™” ì‹œì‘ ì˜¤ë¥˜:', error);
    }
  };

  // ë…¹í™” ì¤‘ì§€
  const stopRecording = () => {
    if (mediaRecorderRef.current && recordingState.isRecording) {
      mediaRecorderRef.current.stop();
    }
  };

  // ë‹¤ìš´ë¡œë“œ URL ìƒì„±
  useEffect(() => {
    if (recordingState.recordedChunks.length > 0 && !recordingState.isRecording) {
      const blob = new Blob(recordingState.recordedChunks, { type: 'video/webm' });
      const url = URL.createObjectURL(blob);
      setRecordingState(prev => ({ ...prev, downloadUrl: url }));
      
      if (onVideoProcessed) {
        onVideoProcessed(blob);
      }
      
      return () => {
        cleanupObjectUrl(url);
      };
    }
  }, [recordingState.recordedChunks, recordingState.isRecording, onVideoProcessed]);

  // ë¹„ë””ì˜¤ ì¬ìƒ/ì¼ì‹œì •ì§€ í† ê¸€
  const togglePlayback = () => {
    const video = videoRef.current;
    if (!video || webcamStream) return;

    if (video.paused) {
      video.play();
    } else {
      video.pause();
    }
  };

  return (
    <div className="bg-white rounded-lg shadow-md p-6">
      <h2 className="text-xl font-semibold mb-4">ë¹„ë””ì˜¤ í¸ì§‘ê¸°</h2>
      
      {/* ë””ë²„ê¹…ìš© ë¹„ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸° */}
      <div className="mb-4 p-4 bg-gray-50 rounded-lg">
        <h3 className="text-sm font-medium mb-2">ì›ë³¸ ì˜ìƒ (ë””ë²„ê¹…ìš©)</h3>
        <video
          ref={videoRef}
          className="w-64 h-auto border rounded"
          playsInline
          controls={!!videoFile}
        />
      </div>
      
      {/* ìº”ë²„ìŠ¤ ë¯¸ë¦¬ë³´ê¸° */}
      <div className="mb-4">
        <h3 className="text-sm font-medium mb-2">í¸ì§‘ëœ ì˜ìƒ</h3>
        <canvas
          ref={canvasRef}
          className="w-full max-h-96 bg-black rounded-lg border"
          style={{ aspectRatio: '16/9' }}
        />
        
        {/* ìƒíƒœ ì •ë³´ */}
        <div className="mt-2 text-xs text-gray-500 space-y-1">
          <div>ìº”ë²„ìŠ¤ í¬ê¸°: {debugInfo.canvasWidth} Ã— {debugInfo.canvasHeight}</div>
          <div>ë¹„ë””ì˜¤ í¬ê¸°: {debugInfo.videoWidth} Ã— {debugInfo.videoHeight}</div>
          <div>ë¹„ë””ì˜¤ ìƒíƒœ: {debugInfo.readyState} (2=ë¡œë“œë¨, 4=ì¬ìƒê°€ëŠ¥)</div>
          <div>ì†ŒìŠ¤ íƒ€ì…: {debugInfo.sourceType}</div>
          {overlayImageElement && (
            <div>ì˜¤ë²„ë ˆì´: {overlayImageElement.width} Ã— {overlayImageElement.height}</div>
          )}
        </div>
      </div>

      {/* ì»¨íŠ¸ë¡¤ íŒ¨ë„ */}
      <div className="space-y-4">
        {/* ì¬ìƒ ì»¨íŠ¸ë¡¤ */}
        {videoFile && (
          <div className="flex items-center gap-2">
            <button
              onClick={togglePlayback}
              className="px-4 py-2 bg-gray-500 text-white rounded-lg hover:bg-gray-600"
            >
              â¯ï¸ ì¬ìƒ/ì¼ì‹œì •ì§€
            </button>
          </div>
        )}

        {/* í˜ì´ì§€ ì˜¤ë””ì˜¤ ì„¤ì • */}
        <div className="flex items-center gap-4 p-4 bg-blue-50 border border-blue-200 rounded-lg">
          <div className="flex items-center gap-2">
            <span className="text-sm font-medium">í˜ì´ì§€ ì˜¤ë””ì˜¤ ìº¡ì²˜:</span>
            <div className={`w-3 h-3 rounded-full ${audioSettings.enabled ? 'bg-green-500' : 'bg-gray-400'}`}></div>
            <span className="text-sm">{audioSettings.enabled ? `í™œì„±í™”ë¨ (${audioSettings.detectedElements}ê°œ ìš”ì†Œ)` : 'ë¹„í™œì„±í™”ë¨'}</span>
          </div>
          {!audioSettings.enabled && (
            <button
              onClick={enablePageAudio}
              className="px-4 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 text-sm"
            >
              ğŸ”Š í˜ì´ì§€ ì˜¤ë””ì˜¤ í™œì„±í™”
            </button>
          )}
          <div className="text-xs text-gray-600">
            ì›¹í˜ì´ì§€ ë‚´ ëª¨ë“  ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ìš”ì†Œì˜ ì†Œë¦¬ë¥¼ ë…¹í™”ì— í¬í•¨í•©ë‹ˆë‹¤
          </div>
        </div>

        {/* ë…¹í™” ì»¨íŠ¸ë¡¤ */}
        <div className="flex items-center gap-4">
          {!recordingState.isRecording ? (
            <button
              onClick={startRecording}
              className="px-6 py-3 bg-red-500 text-white rounded-lg hover:bg-red-600 flex items-center gap-2"
            >
              ğŸ”´ ë…¹í™” ì‹œì‘
            </button>
          ) : (
            <button
              onClick={stopRecording}
              className="px-6 py-3 bg-gray-500 text-white rounded-lg hover:bg-gray-600 flex items-center gap-2"
            >
              â¹ï¸ ë…¹í™” ì¤‘ì§€
            </button>
          )}
          
          {recordingState.isRecording && (
            <div className="flex items-center gap-2 text-red-500">
              <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
              <span>ë…¹í™” ì¤‘: {formatTime(recordingState.recordingTime)}</span>
            </div>
          )}
        </div>

        {/* ë‹¤ìš´ë¡œë“œ */}
        {recordingState.downloadUrl && (
          <div className="p-4 bg-green-50 border border-green-200 rounded-lg">
            <p className="text-green-700 mb-2">âœ… ë…¹í™” ì™„ë£Œ!</p>
            <a
              href={recordingState.downloadUrl}
              download="edited_video.webm"
              className="inline-block px-4 py-2 bg-green-500 text-white rounded-lg hover:bg-green-600"
            >
              ğŸ“¥ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
            </a>
          </div>
        )}
      </div>
    </div>
  );
};

export default VideoEditor;